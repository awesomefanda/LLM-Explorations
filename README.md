# LLM-Explorations ğŸš€

Welcome to my AI and Large Language Model (LLM) laboratory. This repository is a dedicated space for my journey into the world of Generative AI, where I document experiments, build prototypes, and explore the cutting edge of machine intelligence.

## ğŸ“Œ About This Repo
The goal of this repository is to track my learning progress from basic LLM implementations to complex multimodal pipelines. Each folder represents a different milestone or experiment in AI.

## ğŸ“‚ Current Projects

### ğŸ¬ [AI-Scene-Maker](./AI-Scene-Maker)
A Multimodal pipeline that converts text scripts into narrated visual scenes.
* **Status:** Image + Voiceover (Phase 1)
* **Tech:** Kokoro TTS, Stable Diffusion, MoviePy
* **Goal:** Evolving into a full motion-picture generation engine.

*(More project links will come here as I create them!)*

## ğŸ› ï¸ Tech Stack & Tools
Throughout this repo, I'll be experimenting with:
- **Models:** OpenAI, Anthropic, Hugging Face Transformers, Kokoro, Stable Diffusion.
- **Frameworks:** LangChain, PyTorch, Diffusers.
- **Libraries:** MoviePy, NumPy, Pandas, Scikit-learn.

## ğŸ¯ Learning Roadmap
- [x] Setting up the AI Environment & CUDA
- [x] Text-to-Image & Text-to-Speech Integration
- [ ] Prompt Engineering & RAG (Retrieval-Augmented Generation)
- [ ] Fine-tuning Small Language Models (SLMs)
- [ ] Agentic Workflows
- [ ] Text-to-Video / Motion Generation

## âš™ï¸ Setup Notes
Most projects will require a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt